{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import logging\n",
    "import datetime as dt\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "BATCH_SIZE = 1\n",
    "SIZE = 128\n",
    "USE_MIXUP = True\n",
    "MIXUP_PROB = 0.275\n",
    "\n",
    "LR = 1e-3\n",
    "PATIENCE = 10\n",
    "LR_FACTOR = 0.8\n",
    "use_noisy = True\n",
    "use_augmented = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/rio114/keras-cnn-with-lwlrap-evaluation/\n",
    "def tf_one_sample_positive_class_precisions(y_true, y_pred) :\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    \n",
    "    # find true labels\n",
    "    pos_class_indices = tf.where(y_true == 1) \n",
    "    \n",
    "    # put rank on each element\n",
    "    retrieved_classes = tf.nn.top_k(y_pred, k=num_classes).indices\n",
    "    sample_range = tf.zeros(shape=tf.shape(tf.transpose(y_pred)), dtype=tf.int32)\n",
    "    sample_range = tf.add(sample_range, tf.range(tf.shape(y_pred)[0], delta=1))\n",
    "    sample_range = tf.transpose(sample_range)\n",
    "    sample_range = tf.reshape(sample_range, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_classes = tf.reshape(retrieved_classes, (-1,num_classes*tf.shape(y_pred)[0]))\n",
    "    retrieved_class_map = tf.concat((sample_range, retrieved_classes), axis=0)\n",
    "    retrieved_class_map = tf.transpose(retrieved_class_map)\n",
    "    retrieved_class_map = tf.reshape(retrieved_class_map, (tf.shape(y_pred)[0], num_classes, 2))\n",
    "    \n",
    "    class_range = tf.zeros(shape=tf.shape(y_pred), dtype=tf.int32)\n",
    "    class_range = tf.add(class_range, tf.range(num_classes, delta=1))\n",
    "    \n",
    "    class_rankings = tf.scatter_nd(retrieved_class_map,\n",
    "                                          class_range,\n",
    "                                          tf.shape(y_pred))\n",
    "    \n",
    "    #pick_up ranks\n",
    "    num_correct_until_correct = tf.gather_nd(class_rankings, pos_class_indices)\n",
    "\n",
    "    # add one for division for \"presicion_at_hits\"\n",
    "    num_correct_until_correct_one = tf.add(num_correct_until_correct, 1) \n",
    "    num_correct_until_correct_one = tf.cast(num_correct_until_correct_one, tf.float32)\n",
    "    \n",
    "    # generate tensor [num_sample, predict_rank], \n",
    "    # top-N predicted elements have flag, N is the number of positive for each sample.\n",
    "    sample_label = pos_class_indices[:, 0]   \n",
    "    sample_label = tf.reshape(sample_label, (-1, 1))\n",
    "    sample_label = tf.cast(sample_label, tf.int32)\n",
    "    \n",
    "    num_correct_until_correct = tf.reshape(num_correct_until_correct, (-1, 1))\n",
    "    retrieved_class_true_position = tf.concat((sample_label, \n",
    "                                               num_correct_until_correct), axis=1)\n",
    "    retrieved_pos = tf.ones(shape=tf.shape(retrieved_class_true_position)[0], dtype=tf.int32)\n",
    "    retrieved_class_true = tf.scatter_nd(retrieved_class_true_position, \n",
    "                                         retrieved_pos, \n",
    "                                         tf.shape(y_pred))\n",
    "    # cumulate predict_rank\n",
    "    retrieved_cumulative_hits = tf.cumsum(retrieved_class_true, axis=1)\n",
    "\n",
    "    # find positive position\n",
    "    pos_ret_indices = tf.where(retrieved_class_true > 0)\n",
    "\n",
    "    # find cumulative hits\n",
    "    correct_rank = tf.gather_nd(retrieved_cumulative_hits, pos_ret_indices)  \n",
    "    correct_rank = tf.cast(correct_rank, tf.float32)\n",
    "\n",
    "    # compute presicion\n",
    "    precision_at_hits = tf.truediv(correct_rank, num_correct_until_correct_one)\n",
    "\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "def tf_lwlrap(y_true, y_pred):\n",
    "    num_samples, num_classes = y_pred.shape\n",
    "    pos_class_indices, precision_at_hits = (tf_one_sample_positive_class_precisions(y_true, y_pred))\n",
    "    pos_flgs = tf.cast(y_true > 0, tf.int32)\n",
    "    labels_per_class = tf.reduce_sum(pos_flgs, axis=0)\n",
    "    weight_per_class = tf.truediv(tf.cast(labels_per_class, tf.float32),\n",
    "                                  tf.cast(tf.reduce_sum(labels_per_class), tf.float32))\n",
    "    sum_precisions_by_classes = tf.zeros(shape=(num_classes), dtype=tf.float32)  \n",
    "    class_label = pos_class_indices[:,1]\n",
    "    sum_precisions_by_classes = tf.math.unsorted_segment_sum(precision_at_hits,\n",
    "                                                        class_label,\n",
    "                                                       num_classes)\n",
    "    labels_per_class = tf.cast(labels_per_class, tf.float32)\n",
    "    labels_per_class = tf.add(labels_per_class, 1e-7)\n",
    "    per_class_lwlrap = tf.truediv(sum_precisions_by_classes,\n",
    "                                  tf.cast(labels_per_class, tf.float32))\n",
    "    out = tf.cast(tf.tensordot(per_class_lwlrap, weight_per_class, axes=1), dtype=tf.float32)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :]))\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "            precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "    # a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "    sample_weight = np.sum(truth > 0, axis=1)\n",
    "    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "    overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0, \n",
    "      scores[nonzero_weight_sample_indices, :],\n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "    return overall_lwlrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import regularizers\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Sequence):\n",
    "    \"\"\"Creating data generator\"\"\"\n",
    "    def __init__(self, mels, labels):\n",
    "        super().__init__()\n",
    "        self.mels = mels\n",
    "        self.labels = labels\n",
    "        self.transforms = iaa.Sequential([\n",
    "            iaa.CoarseDropout(0.1,size_percent=0.02)\n",
    "        ])\n",
    "    \n",
    "    def getitem(self,image):\n",
    "        image = Image.fromarray(image, mode='L')        \n",
    "        time_dim, base_dim = image.size\n",
    "        crop = random.randint(0, time_dim - base_dim)\n",
    "        image = image.crop([crop, 0, crop + base_dim, base_dim])\n",
    "        image = np.array(image)\n",
    "        image = tf.divide(self.transforms(images=image),255)\n",
    "        image = np.expand_dims(image,-1)\n",
    "        image = preprocess_input(image)\n",
    "        return image\n",
    "    \n",
    "    def create_generator(self, batch_size, shuffling=False, test_data=False):\n",
    "        while True:\n",
    "            train_X,train_y = self.mels,self.labels\n",
    "            if shuffling:\n",
    "                train_X,train_y = shuffle(train_X,train_y)\n",
    "\n",
    "            for start in range(0, len(train_y), batch_size):\n",
    "                end = min(start + batch_size, len(train_X))\n",
    "                batch_data = []\n",
    "                X_train_batch = train_X[start:end]\n",
    "                for i in range(len(X_train_batch)):\n",
    "                    image = self.getitem(X_train_batch[i])\n",
    "                    batch_data.append(image) \n",
    "                if test_data == False:\n",
    "                    batch_labels = train_y[start:end]\n",
    "                    \n",
    "                if test_data == False:\n",
    "                    yield np.array(batch_data, np.float32), batch_labels.astype('float32') \n",
    "                else:\n",
    "                    yield np.array(batch_data, np.float32)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class SnapshotEnsemble(tf.keras.callbacks.Callback):\n",
    "    \"\"\"snapshot ensemble with custom learning rate schedule\"\"\"\n",
    "    # constructor\n",
    "    def __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
    "        self.epochs = n_epochs\n",
    "        self.cycles = n_cycles\n",
    "        self.lr_max = lrate_max\n",
    "        self.lrates = list()\n",
    "\n",
    "    # calculate learning rate for epoch\n",
    "    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
    "        epochs_per_cycle = math.floor(n_epochs/n_cycles)\n",
    "        cos_inner = (math.pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "        return lrate_max/2 * (math.cos(cos_inner) + 1)\n",
    "\n",
    "    # calculate and set learning rate at the start of the epoch\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        # calculate learning rate\n",
    "        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
    "        # set learning rate\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        # log value\n",
    "        self.lrates.append(lr)\n",
    "\n",
    "    # save models at the end of each cycle\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # check if we can save model\n",
    "        epochs_per_cycle = math.floor(self.epochs / self.cycles)\n",
    "        if epoch != 0 and (epoch + 1) % epochs_per_cycle == 0:\n",
    "            # save model to file\n",
    "            filename = \"snapshot_model_%d.h5\" % int((epoch + 1) / epochs_per_cycle)\n",
    "            self.model.save(filename)\n",
    "            print('>saved snapshot %s, epoch %d' % (filename, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = SnapshotEnsemble(400, 400/50, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_models(n_models):\n",
    "    \"\"\"Loading all saved ensemble models\"\"\"\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = 'snapshot_model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename,compile=False)\n",
    "        model.compile(loss=BCEwithLogits, optimizer=Adam(lr=LR), metrics=[tf_lwlrap])\n",
    "        # add to list of members\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    " \n",
    "def ensemble_predictions(members, testX,testY,test=False):\n",
    "    \"\"\"make an ensemble prediction for multi-class classification\"\"\"\n",
    "    # make predictions\n",
    "    yhats = []\n",
    "    for model in members:    \n",
    "        validation_generator = Dataset(testX,testY).create_generator(batch_size=BATCH_SIZE,test_data=test)\n",
    "        print('gen shape = ',next(validation_generator)[0].shape)\n",
    "        pred_val_y = model.predict(validation_generator,steps=len(testX)//BATCH_SIZE+1,verbose=1)\n",
    "        print('pred val y shape = ',pred_val_y.shape)\n",
    "        for i in range(1):\n",
    "            validation_generator = Dataset(testX,testY).create_generator(batch_size=BATCH_SIZE,test_data=test)\n",
    "            pred_val_y += model.predict(validation_generator,steps=len(testX)//BATCH_SIZE+1,verbose=1)\n",
    "    yhats.append(pred_val_y/1)\n",
    "    yhats = np.array(yhats)\n",
    "    # sum across ensemble members\n",
    "    summed = np.sum(yhats, axis=0)\n",
    "    # argmax across classes\n",
    "    result = np.divide(summed, 3)\n",
    "    return result\n",
    " \n",
    "def evaluate_n_members(members, n_members, testX, testy,test=False):\n",
    "    \"\"\"evaluate a specific number of members in an ensemble\"\"\"\n",
    "    # select a subset of members\n",
    "    subset = members[:n_members]\n",
    "    # make prediction\n",
    "    yhat = ensemble_predictions(subset, testX,testy,test=test)\n",
    "    print('true, predicted = ',yhat.shape)\n",
    "    if test==True:\n",
    "        return yhat\n",
    "    # calculate accuracy\n",
    "    return calculate_overall_lwlrap_sklearn(testy, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate binary cross entropy\n",
    "def BCEwithLogits(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred, from_logits=True), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import max_norm, MinMaxNorm\n",
    "def get_model(lr=0.001, trainable = True, print_model=True):\n",
    "    nclass = 80\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(None, 128, 1), trainable = trainable, axis=2))\n",
    "    model.add(Conv2D(filters=192, kernel_size=3, input_shape=(1016, 128, 1), padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', \n",
    "                     kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization(trainable = trainable))\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    model.add(Conv2D(filters=192, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', \n",
    "              kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization(trainable = trainable))\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization(trainable = trainable))\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization(trainable = trainable))\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization(trainable = trainable))\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization(trainable = trainable))\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=1024, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\", trainable = trainable,  kernel_initializer='he_uniform', kernel_constraint=max_norm(2.)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(PReLU(shared_axes=[1,2]))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    model.add(SpatialDropout2D(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters=nclass, kernel_size=(1,1), padding=\"valid\", trainable = trainable,  kernel_initializer='he_uniform', activation=\"sigmoid\"))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(80,activation='linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(conf, pathname, trim_long_data):\n",
    "    \"\"\"loading the audio files and applying some effects\"\"\"\n",
    "    y, sr = librosa.load(pathname, sr=conf.sampling_rate)\n",
    "    if 0 < len(y):\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "\n",
    "    if len(y) > conf.samples:\n",
    "        if trim_long_data:\n",
    "            y = y[0:0+conf.samples]\n",
    "    else:\n",
    "        padding = conf.samples - len(y)\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, conf.samples - len(y) - offset), conf.padmode)\n",
    "    return y\n",
    "\n",
    "\n",
    "def audio_to_melspectrogram(conf, audio):\n",
    "    \"\"\"Converting audio to spectograms\"\"\"\n",
    "    spectrogram = librosa.feature.melspectrogram(audio, \n",
    "                                                 sr=conf.sampling_rate,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n",
    "    \"\"\"print the spectogram image\"\"\"\n",
    "    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n",
    "                             sr=conf.sampling_rate, hop_length=conf.hop_length,\n",
    "                            fmin=conf.fmin, fmax=conf.fmax)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def read_as_melspectrogram(conf, pathname, trim_long_data, debug_display=False):\n",
    "    \"\"\"single function for reading and converting the audio to spectrogram\"\"\"\n",
    "    x = read_audio(conf, pathname, trim_long_data)\n",
    "    mels = audio_to_melspectrogram(conf, x)\n",
    "    if debug_display:\n",
    "        IPython.display.display(IPython.display.Audio(x, rate=conf.sampling_rate))\n",
    "        show_melspectrogram(conf, mels)\n",
    "    return mels\n",
    "\n",
    "\n",
    "class conf:\n",
    "    sampling_rate = 44100\n",
    "    duration = 2 # sec\n",
    "    hop_length = 347*duration # to make time steps 128\n",
    "    fmin = 20\n",
    "    fmax = sampling_rate // 2\n",
    "    n_mels = 128\n",
    "    n_fft = n_mels * 20\n",
    "    padmode = 'constant'\n",
    "    samples = sampling_rate * duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "def transform(conf, pathname: Path, cmd=[]):\n",
    "    \"\"\"applying some audio augmentations with sox\"\"\"\n",
    "    cmd = [\"sox\", str(pathname), \"output.wav\"] + cmd\n",
    "    sp.run(cmd)\n",
    "\n",
    "    augmented = read_audio(conf, Path(\"output.wav\"), trim_long_data=False)\n",
    "    mels_augmented = audio_to_melspectrogram(conf, augmented)\n",
    "    return mels_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n",
    "    \"\"\"Normalize and standardize the audio\"\"\"\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    X = X - mean\n",
    "    std = std or X.std()\n",
    "    Xstd = X / (std + eps)\n",
    "    _min, _max = Xstd.min(), Xstd.max()\n",
    "    norm_max = norm_max or _max\n",
    "    norm_min = norm_min or _min\n",
    "    if (_max - _min) > eps:\n",
    "        # Normalize to [0, 255]\n",
    "        V = Xstd\n",
    "        V[V < norm_min] = norm_min\n",
    "        V[V > norm_max] = norm_max\n",
    "        V = 255 * (V - norm_min) / (norm_max - norm_min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        # Just zero\n",
    "        V = np.zeros_like(Xstd, dtype=np.uint8)\n",
    "    return V\n",
    "\n",
    "def convert_wav_to_image(df, source,test_data=False):\n",
    "    \"\"\"applying all the transformations above\"\"\"\n",
    "    curated = []\n",
    "    eq = []\n",
    "    tb = []\n",
    "    tbup = []\n",
    "    reverb = []\n",
    "    fade = []\n",
    "    pitchup = []\n",
    "    pitchdn = []\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        file = source + '/' + str(row.fname)\n",
    "        augs = [transform(conf, file, cmd=[\"gain\", \"-h\", \"equalizer\", \"2400\", \"3q\", \"8\"]),\\\n",
    "        transform(conf, file, cmd=[\"gain\", \"-h\", \"treble\", \"-30\", \"bass\", \"-30\"]),\\\n",
    "        transform(conf, file, cmd=[\"gain\", \"-h\", \"treble\", \"+20\", \"bass\", \"+20\"]),\\\n",
    "        transform(conf, file, cmd=[\"reverb\"]),\\\n",
    "        transform(conf, file, cmd=[\"fade\", \"q\", \"3\"]),\\\n",
    "        transform(conf, file, cmd=[\"pitch\", \"+500\"]),\\\n",
    "        transform(conf, file, cmd=[\"pitch\", \"-500\"])]\n",
    "        for i,j in zip(augs,[eq,tb,tbup,reverb,fade,pitchup,pitchdn]):\n",
    "            x_color = normalize(i)\n",
    "            j.append(x_color)\n",
    "        x = read_as_melspectrogram(conf, file, trim_long_data=False)\n",
    "        x_color = normalize(x)\n",
    "        curated.append(x_color)\n",
    "    return curated,eq,tb,tbup,reverb,fade,pitchup,pitchdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(x,source):\n",
    "    \"\"\"Final function 1: takes raw data and source folder and returns predictions\"\"\"\n",
    "    x_train,x_eq,x_tb,x_tbup,x_reverb,x_fade,x_pitchup,x_pitchdn = convert_wav_to_image(x,source,test_data=True)\n",
    "    x_aug = x_train + x_fade + x_pitchup + x_reverb + x_tb + x_pitchup + x_eq + x_tbup\n",
    "\n",
    "    # load models in order\n",
    "    members = load_all_models(1)\n",
    "    print('Loaded %d models' % len(members))\n",
    "    # reverse loaded models so we build the ensemble with the last models first\n",
    "    members = list(reversed(members))\n",
    "    y_pred = evaluate_n_members(members,1, x_aug, x_aug,test=True)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_curated_df = pd.read_csv('train_curated.csv')\n",
    "trn_curated_df = trn_curated_df.drop(['labels'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533ab2cd1a7e41ac9e10bea68712c604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">loaded snapshot_model_1.h5\n",
      "Loaded 1 models\n",
      "data gen =  0 1\n",
      "gen shape =  (128, 128, 1)\n",
      "data gen =  1 2\n",
      "data gen =  2 3\n",
      "data gen =  3 4\n",
      "data gen =  4 5\n",
      "data gen =  5 6\n",
      "data gen =  6 7\n",
      "1/9 [==>...........................] - ETA: 3sdata gen =  7 8\n",
      "2/9 [=====>........................] - ETA: 2sdata gen =  0 1\n",
      "3/9 [=========>....................] - ETA: 1sdata gen =  1 2\n",
      "4/9 [============>.................] - ETA: 1sdata gen =  2 3\n",
      "5/9 [===============>..............] - ETA: 1sdata gen =  3 4\n",
      "6/9 [===================>..........] - ETA: 0sdata gen =  4 5\n",
      "7/9 [======================>.......] - ETA: 0sdata gen =  5 6\n",
      "8/9 [=========================>....] - ETA: 0sdata gen =  6 7\n",
      "9/9 [==============================] - 2s 267ms/step\n",
      "pred val y shape =  (9, 80)\n",
      "data gen =  0 1\n",
      "data gen =  1 2\n",
      "data gen =  2 3\n",
      "data gen =  3 4\n",
      "data gen =  4 5\n",
      "data gen =  5 6\n",
      "1/9 [==>...........................] - ETA: 2sdata gen =  6 7\n",
      "2/9 [=====>........................] - ETA: 1sdata gen =  7 8\n",
      "3/9 [=========>....................] - ETA: 1sdata gen =  0 1\n",
      "4/9 [============>.................] - ETA: 1sdata gen =  1 2\n",
      "5/9 [===============>..............] - ETA: 0sdata gen =  2 3\n",
      "6/9 [===================>..........] - ETA: 0sdata gen =  3 4\n",
      "7/9 [======================>.......] - ETA: 0sdata gen =  4 5\n",
      "8/9 [=========================>....] - ETA: 0sdata gen =  5 6\n",
      "9/9 [==============================] - 2s 209ms/step\n",
      "true, predicted =  (9, 80)\n"
     ]
    }
   ],
   "source": [
    "result = final(trn_curated_df[:1],'FSDKaggle2019.audio_train_curated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 80)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final2(x,y,source):\n",
    "    \"\"\"Takes data, labels, source folder and returns score of the predictions\"\"\"\n",
    "    x_train,x_eq,x_tb,x_tbup,x_reverb,x_fade,x_pitchup,x_pitchdn = convert_wav_to_image(x,source,test_data=False)\n",
    "    x_aug = x_train + x_fade + x_pitchup + x_reverb + x_tb + x_pitchup + x_eq + x_tbup\n",
    "\n",
    "    # load models in order\n",
    "    members = load_all_models(1)\n",
    "    print('Loaded %d models' % len(members))\n",
    "    # reverse loaded models so we build the ensemble with the last models first\n",
    "    members = list(reversed(members))\n",
    "    \n",
    "    labels = []\n",
    "    with (open(\"labels.pkl\", \"rb\")) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                labels.append(pickle.load(openfile))\n",
    "            except EOFError:\n",
    "                break\n",
    "    labels = labels[0]           \n",
    "    y_train = np.zeros((len(x), 80)).astype(int)\n",
    "    for i, row in enumerate(y.str.split(',')):\n",
    "        for label in row:\n",
    "            idx = labels.index(label)\n",
    "            y_train[i, idx] = 1\n",
    "    y_pred = evaluate_n_members(members, 1, x_aug, y_train,test=False)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d8f909c30b4a3a9282a8b5a85cf79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-921f6efab678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_curated_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_curated_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfinal2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FSDKaggle2019.audio_train_curated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-195-ba3823bdf3a7>\u001b[0m in \u001b[0;36mfinal2\u001b[0;34m(x, y, source)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinal2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Takes data, labels, source folder and returns score of the predictions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_eq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tbup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_reverb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_fade\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_pitchup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_pitchdn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_wav_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_fade\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_pitchup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_reverb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_tb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_pitchup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_eq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_tbup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-190-6bd00f505a23>\u001b[0m in \u001b[0;36mconvert_wav_to_image\u001b[0;34m(df, source, test_data)\u001b[0m\n\u001b[1;32m     35\u001b[0m         augs = [transform(conf, file, cmd=[\"gain\", \"-h\", \"equalizer\", \"2400\", \"3q\", \"8\"]),\\\n\u001b[1;32m     36\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"treble\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-30\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-30\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"treble\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"+20\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"+20\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reverb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fade\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-189-38f2367a76bd>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(conf, pathname, cmd)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maugmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_long_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmels_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_to_melspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmels_augmented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-ef1a026bb42f>\u001b[0m in \u001b[0;36maudio_to_melspectrogram\u001b[0;34m(conf, audio)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                  \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                  \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                                  fmax=conf.fmax)\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trn_curated_df = pd.read_csv('train_curated.csv')\n",
    "x = trn_curated_df[:1000].drop(['labels'],axis=1)\n",
    "y = trn_curated_df[:1000]['labels']\n",
    "final2(x,y,'FSDKaggle2019.audio_train_curated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
